# ===========================================
# Marie Chat - Environment Variables
# ===========================================
# Copy this file to .env and fill in your actual values
# cp env.example .env

# ===========================================
# Application Configuration
# ===========================================

# Flask Environment (development, production, testing)
FLASK_ENV=development

# Flask Secret Key (for sessions, CSRF protection, etc.)
FLASK_SECRET_KEY=your-flask-secret-key-change-this-in-production

# Flask Host and Port
FLASK_HOST=0.0.0.0
FLASK_PORT=5000

# Debug Mode (set to False in production)
FLASK_DEBUG=true

# CORS Configuration (comma-separated origins, or * for all)
CORS_ORIGINS=http://localhost:3000,http://localhost:3001

# ===========================================
# OpenSearch Configuration
# ===========================================

# OpenSearch connection URLs (comma-separated for clusters)
OPENSEARCH_HOSTS=https://localhost:9200

# OpenSearch authentication
OPENSEARCH_USER=admin
OPENSEARCH_PASSWORD=your-secure-password-here

# SSL Configuration
OPENSEARCH_USE_SSL=true
OPENSEARCH_VERIFY_CERTS=false

# OpenSearch connection timeout (seconds)
OPENSEARCH_TIMEOUT=30

# OpenSearch max retries
OPENSEARCH_MAX_RETRIES=3

# ===========================================
# JWT Authentication
# ===========================================

# JWT Secret Key (MUST be strong and unique in production)
JWT_SECRET_KEY=your-super-secret-jwt-key-change-this-in-production

# JWT Access Token Expiration (hours)
JWT_ACCESS_TOKEN_EXPIRES=1

# JWT Refresh Token Expiration (days)
JWT_REFRESH_TOKEN_EXPIRES=30

# JWT Algorithm
JWT_ALGORITHM=HS256

# ===========================================
# LLM Providers Configuration
# ===========================================

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434

# HuggingFace Configuration
HUGGINGFACE_API_KEY=hf_your_api_key_here

# Default LLM Provider (ollama, huggingface)
DEFAULT_LLM_PROVIDER=ollama

# Default LLM Model (depends on provider)
DEFAULT_LLM_MODEL=llama3.2

# LLM Temperature (0.0 to 2.0)
DEFAULT_LLM_TEMPERATURE=0.7

# LLM Max Tokens
DEFAULT_LLM_MAX_TOKENS=2048

# ===========================================
# Embedding Configuration
# ===========================================

# Default Embedding Model (HuggingFace model ID)
# Recommended: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2

# Embedding Dimension (usually 384 or 768)
EMBEDDING_DIMENSION=384

# Embedding Device (cpu, cuda, mps)
EMBEDDING_DEVICE=cpu

# ===========================================
# Speech Services Configuration
# ===========================================

# TTS (Text-to-Speech) Configuration
# Recommended: coqui/XTTS-v2 or edge-tts (no model needed)
DEFAULT_TTS_MODEL=coqui/XTTS-v2

# TTS Provider (edge-tts, coqui, pyttsx3)
DEFAULT_TTS_PROVIDER=edge-tts

# STT (Speech-to-Text) Configuration
# Recommended: openai/whisper-base
DEFAULT_STT_MODEL=openai/whisper-base

# STT Provider (faster-whisper, whisper, wav2vec2)
DEFAULT_STT_PROVIDER=faster-whisper

# STT Device (cpu, cuda, mps)
STT_DEVICE=cpu

# STT Model Size (tiny, base, small, medium, large)
STT_MODEL_SIZE=base

# ===========================================
# File Storage Configuration
# ===========================================

# Media files directory (user uploaded files)
MEDIA_ROOT=./media

# Maximum file size (in bytes, e.g., 10MB = 10485760)
MAX_FILE_SIZE=10485760

# Allowed file extensions (comma-separated)
ALLOWED_EXTENSIONS=pdf,docx,doc,txt,md,csv,xlsx,xls,pptx,ppt,py,js,ts,java,cpp,c,go,rs,rb,php,html,css,json,xml,yaml,yml,jpg,jpeg,png,gif,webp,bmp,zip,tar,gz

# ===========================================
# API Configuration
# ===========================================

# API Rate Limiting
# Default rate limit per API key (requests per hour)
DEFAULT_RATE_LIMIT=1000

# Maximum rate limit that can be configured
MAX_RATE_LIMIT=10000

# API Key prefix
API_KEY_PREFIX=mc_

# API Key expiration (days, 0 = no expiration)
DEFAULT_API_KEY_EXPIRATION_DAYS=0

# ===========================================
# Frontend Configuration (Next.js)
# ===========================================

# Public API URL (used by frontend)
NEXT_PUBLIC_API_URL=http://localhost:5000

# Public WebSocket URL (used by frontend)
NEXT_PUBLIC_WS_URL=ws://localhost:5000

# Frontend Port
NEXT_PUBLIC_PORT=3000

# Frontend Environment
NEXT_PUBLIC_ENV=development

# ===========================================
# Logging Configuration
# ===========================================

# Log Level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Log File Path
LOG_FILE=./logs/marie_chat.log

# Enable File Logging
ENABLE_FILE_LOGGING=true

# Enable Console Logging
ENABLE_CONSOLE_LOGGING=true

# Log Format
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s

# ===========================================
# Admin Configuration
# ===========================================

# Initial Admin Email (for first-time setup)
INITIAL_ADMIN_EMAIL=admin@example.com

# Initial Admin Password (change after first login)
INITIAL_ADMIN_PASSWORD=ChangeThisPassword123!

# Enable Admin Panel
ENABLE_ADMIN_PANEL=true

# ===========================================
# Security Configuration
# ===========================================

# Password hashing rounds (bcrypt)
BCRYPT_ROUNDS=12

# Session timeout (minutes)
SESSION_TIMEOUT=60

# Enable HTTPS redirect (set to true in production)
ENABLE_HTTPS_REDIRECT=false

# Trusted proxies (comma-separated IPs)
TRUSTED_PROXIES=

# ===========================================
# Database/OpenSearch Indices Configuration
# ===========================================

# Number of shards per index
OPENSEARCH_NUMBER_OF_SHARDS=1

# Number of replicas per index
OPENSEARCH_NUMBER_OF_REPLICAS=0

# Index refresh interval (seconds)
OPENSEARCH_REFRESH_INTERVAL=1s

# ===========================================
# Memory Configuration
# ===========================================

# Enable conversational memory
ENABLE_CONVERSATIONAL_MEMORY=true

# Memory extraction batch size
MEMORY_EXTRACTION_BATCH_SIZE=10

# Memory retrieval limit
MEMORY_RETRIEVAL_LIMIT=5

# ===========================================
# Feature Flags
# ===========================================

# Enable file uploads
ENABLE_FILE_UPLOADS=true

# Enable voice features (TTS/STT)
ENABLE_VOICE_FEATURES=true

# Enable conversation referencing
ENABLE_CONVERSATION_REFERENCING=true

# Enable follow-up questions
ENABLE_FOLLOW_UP_QUESTIONS=true

# Enable multilingual memory
ENABLE_MULTILINGUAL_MEMORY=true

# Enable admin panel
ENABLE_ADMIN_PANEL=true

# Enable API for developers
ENABLE_DEVELOPER_API=true

# ===========================================
# Docker Configuration (for docker-compose)
# ===========================================

# Docker network name
DOCKER_NETWORK=marie_chat_network

# OpenSearch cluster name (for Docker)
OPENSEARCH_CLUSTER_NAME=marie-cluster

# OpenSearch node name (for Docker)
OPENSEARCH_NODE_NAME=marie-node-1

# OpenSearch Java options (for Docker)
OPENSEARCH_JAVA_OPTS=-Xms1g -Xmx1g

# ===========================================
# Development/Testing
# ===========================================

# Enable API documentation (Swagger/OpenAPI)
ENABLE_API_DOCS=true

# API Documentation URL
API_DOCS_URL=/api/docs

# Enable development tools
ENABLE_DEV_TOOLS=false

# Mock LLM responses (for testing without actual LLM)
MOCK_LLM_RESPONSES=false

# ===========================================
# Monitoring & Analytics (Optional)
# ===========================================

# Enable analytics
ENABLE_ANALYTICS=false

# Analytics endpoint (if using external service)
ANALYTICS_ENDPOINT=

# Enable error tracking (Sentry, etc.)
ENABLE_ERROR_TRACKING=false

# Error tracking DSN (Sentry DSN, etc.)
ERROR_TRACKING_DSN=
